import torch
import matplotlib.pyplot as plt
import numpy as np

from typing import Dict, Tuple

from models.vae import VAE
from models.diffusion import NoiseScheduler, sample
from models.LDM import LDMVAE

def plotGANGeneratorSamples(results: Dict[str, list], step: int=1):
    genSamples = results["generator_samples"]
    epochs = len(genSamples)
    imgsPerSample = genSamples[0].size(0)

    assert epochs >= step, f"No epochs matched the step={step}. try a smaller step"

    selectedEpochs = [i for i in range(step, epochs+1, step)]
    selectedSamples = [genSamples[i-1] for i in selectedEpochs]
    numCols = len(selectedEpochs)

    # Create a series of subplots
    fig, axs = plt.subplots(nrows=imgsPerSample,
                            ncols=numCols,
                            figsize=(epochs, imgsPerSample)
                            )
    
    for col, genSample in enumerate(selectedSamples):
        genSample = genSample.detach().cpu()

        # permute samples from BCHW -> BHWC (make matplotlib friendly)
        permutedSample = genSample.permute(0,2,3,1)
        for sampleIdx, img in enumerate(permutedSample):
            img = img.numpy()
            img = (img + 1) / 2

            ax = axs[sampleIdx, col]
            ax.imshow(img.squeeze(), cmap="gray" if img.shape[-1]==1 else None)
            ax.axis("off")

    bigAx = fig.add_subplot(111, frameon=False)
    bigAx.set_xticks(np.arange(numCols))
    bigAx.set_yticks(np.arange(imgsPerSample))

    bigAx.set_xticklabels([f"{e}" for e in selectedEpochs])
    bigAx.set_yticklabels([f"{i}" for i in range(imgsPerSample)])

    bigAx.set_xlabel("Epoch")
    bigAx.set_ylabel("Latent Sample")
    bigAx.tick_params(labelcolor='black', top=False, bottom=False, left=False, right=False)

    fig.suptitle(f"Images Generated by GAN", fontsize=16)
    
    plt.tight_layout(rect=(0, 0, 1, 0.95))
    plt.show()

def plotVAEDecoderSamples(results: Dict[str, list], step: int=1, title: str=""):
    genSamples = results["decoder_samples"]
    epochs = len(genSamples)
    imgsPerSample = genSamples[0].size(0)

    assert epochs >= step, f"No epochs matched the step={step}. try a smaller step"

    selectedEpochs = [i for i in range(step, epochs+1, step)]
    selectedSamples = [genSamples[i-1] for i in selectedEpochs]
    numCols = len(selectedEpochs)

    # Create a series of subplots
    fig, axs = plt.subplots(nrows=imgsPerSample,
                            ncols=numCols,
                            figsize=(epochs, imgsPerSample)
                            )
    
    for col, genSample in enumerate(selectedSamples):
        genSample = genSample.detach().cpu()

        # permute samples from BCHW -> BHWC (make matplotlib friendly)
        permutedSample = genSample.permute(0,2,3,1)
        for sampleIdx, img in enumerate(permutedSample):
            img = (img + 1) / 2

            ax = axs[sampleIdx, col]
            ax.imshow(img.squeeze(), cmap="gray" if img.shape[-1]==1 else None)
            ax.axis("off")

    bigAx = fig.add_subplot(111, frameon=False)
    bigAx.set_xticks(np.arange(numCols))
    bigAx.set_yticks(np.arange(imgsPerSample))

    bigAx.set_xticklabels([f"{e}" for e in selectedEpochs])
    bigAx.set_yticklabels([f"{i}" for i in range(imgsPerSample)])

    bigAx.set_xlabel("Epoch")
    bigAx.set_ylabel("Latent Sample")
    bigAx.tick_params(labelcolor='black', top=False, bottom=False, left=False, right=False)

    fig.suptitle(title + f" Generated Images", fontsize=16)
    
    plt.tight_layout(rect=(0, 0, 1, 0.95))
    plt.show()

def visualiseVAELatentTraversal(vae: VAE|LDMVAE, 
                             testDataloader: torch.utils.data.DataLoader, 
                             numSamples: int=5, 
                             latentIdx: int|Tuple[int,int,int]=0, 
                             steps: int=10, 
                             title: str="",
                             minZ: int=-3,
                             maxZ: int=3,
                             seed: int=42,
                             device: torch.device="cuda" if torch.cuda.is_available() else "cpu"):
    vae.eval()
    imgsToPlot = []
    labelsToPlot = []
    zVals = torch.linspace(start=minZ, end=maxZ, steps=steps)

    with torch.inference_mode():
        for xBatch, yBatch in testDataloader:
            xBatch = xBatch.to(device)
            for i in range(xBatch.size(0)):
                if len(imgsToPlot) == numSamples:
                    break
                x = xBatch[i].unsqueeze(0)
                y = yBatch[i].item()
                mu, logvar = vae.encode(x)
                
                torch.manual_seed(seed)
                z = vae.reparameterize(mu, logvar)

                travRow = []
                for val in zVals:
                    zdup = z.clone()
                    zdup[0, latentIdx] += val
                    xhat = vae.decode(zdup).squeeze(0).cpu()
                    xhat = (xhat + 1) / 2
                    xhat = xhat.permute(1, 2, 0).numpy()
                    travRow.append(xhat)
                
                imgsToPlot.append(travRow)
                labelsToPlot.append(testDataloader.dataset.classes[y])
            if len(imgsToPlot) == numSamples:
                break

    fig, axes = plt.subplots(nrows=numSamples, 
                            ncols=steps, 
                            figsize=(steps, numSamples))
    if numSamples == 1:
        axes = axes[np.newaxis, :]

    for row in range(numSamples):
        for col in range(steps):
            axes[row, col].imshow(imgsToPlot[row][col])
            axes[row, col].axis('off')
            if row == 0:
                axes[row, col].set_title(f"{zVals[col]:.2f}", fontsize=10)
            if col == 0:
                axes[row, col].set_title(labelsToPlot[row], loc='left', fontsize=10)

    fig.text(0.5, 0.04, 'Latent Value Offset', ha='center')
    plt.suptitle(f"{title} Latent space index: {latentIdx} Traversal")
    plt.tight_layout()
    plt.show()

def plotDiffusionSamples(results: Dict[str, list],
                         step: int=1,
                         title: str=""):
    genSamples = results["generated_samples"]
    epochs = len(genSamples)
    imgsPerSample = genSamples[0].size(0)

    assert epochs >= step, f"No epochs matched the step={step}. try a smaller step"

    selectedEpochs = [i for i in range(step, epochs+1, step)]
    selectedSamples = [genSamples[i-1] for i in selectedEpochs]
    numCols = len(selectedEpochs)

    fig, axs = plt.subplots(nrows=imgsPerSample,
                            ncols=numCols,
                            figsize=(epochs, imgsPerSample))
    
    if imgsPerSample == 1:
        axes = axes[np.newaxis, :]

    for col, genSample in enumerate(selectedSamples):
        genSample = genSample.detach().cpu()
        rangeLabel = [genSample.min().item(), genSample.max().item()]

        permutedSample = genSample.permute(0, 2, 3, 1)
        for sampleIdx, img in enumerate(permutedSample):
            img = (torch.clamp(img, -1, 1) + 1) / 2

            ax = axs[sampleIdx, col]
            ax.imshow(img.squeeze(), cmap="gray" if img.shape[-1]==1 else None)
            ax.axis("off")

            if sampleIdx == 0:
                ax.set_title(f"[{rangeLabel[0]:.1f}, {rangeLabel[1]:.1f}]", fontsize=10)

    bigAx = fig.add_subplot(111, frameon=False)
    bigAx.set_xticks(np.arange(numCols))
    bigAx.set_yticks(np.arange(imgsPerSample))

    bigAx.set_xticklabels([f"{e}" for e in selectedEpochs])
    bigAx.set_yticklabels([f"{i}" for i in range(imgsPerSample)])

    bigAx.set_xlabel("Epoch")
    bigAx.set_ylabel("Latent Sample")
    bigAx.tick_params(labelcolor='black', top=False, bottom=False, left=False, right=False)

    fig.suptitle(title + f" Generated Images", fontsize=16)

    plt.tight_layout()
    plt.show()

def plotDiffusionTtraversalSamples(model: torch.nn.Module,
                                   noiseScheduler: NoiseScheduler,
                                   autoencoder: LDMVAE|None=None,
                                   numSamples: int=1,
                                   imgShape: Tuple[int, int, int]=(3,32,32),
                                   step: int=10,
                                   skip: int=1,
                                   eta: float=1.0,
                                   title: str="",
                                   seed: int | None=None,
                                   device: torch.device="cuda" if torch.cuda.is_available() else "cpu"):
    assert step < noiseScheduler.timesteps, f"sample step must be less than total timesteps. step: {step}, timesteps: {noiseScheduler.timesteps}"
    
    if seed is not None:
        torch.manual_seed(seed)
    xTbatch = torch.randn(numSamples, imgShape[0], imgShape[1], imgShape[2], device=device)
    xtsamples = sample(model=model,
                       noiseScheduler=noiseScheduler,
                       xT=xTbatch,
                       autoencoder=autoencoder,
                       skip=skip,
                       eta=eta,
                       getSteps=step,
                       device=device)
    
    fig, axes = plt.subplots(nrows=numSamples,
                            ncols=len(xtsamples),
                            figsize=(len(xtsamples), numSamples))
    
    if numSamples == 1:
        axes = axes[np.newaxis, :]

    rangeLabels = []
    for col in range(len(xtsamples)):
        rangeLabels.append([xtsamples[col][1].min().item(), xtsamples[col][1].max().item()])
    
    for row in range(numSamples):
        for col in range(len(xtsamples)):
            img = xtsamples[col][1][row].detach().cpu()
            img = (torch.clamp(img, -1, 1) + 1) / 2
            permutedImg = img.permute(1,2,0).numpy()
            axes[row, col].imshow(permutedImg)
            axes[row, col].axis('off')
            if row == 0:
                axes[row, col].set_title(f"t={xtsamples[col][0]} [{rangeLabels[col][0]:.1f}, {rangeLabels[col][1]:.1f}]", fontsize=10)
    
    fig.text(0.5, 0.04, 't value', ha='center')
    plt.suptitle(f"{title} Reverse diffusion (skip: {skip}, eta: {eta})")
    plt.tight_layout()
    plt.show()

def plotForwardDiffusion(dataloader: torch.utils.data.DataLoader,
                         noiseScheduler: NoiseScheduler,
                         numSamples: int=1,
                         step: int=1,
                         title: str="",
                         classLabel: bool=False,
                         seed: int=42):
    device = "cpu"
    batch = next(iter(dataloader))
    assert numSamples <= len(batch[0]), f"numSamples must be less than batch size of dataloader, numSamples: {numSamples}, batch size: {len(batch)}"
    
    torch.manual_seed(seed)
    timesteps = noiseScheduler.timesteps

    tlist = [t for t in range(step, timesteps+1, step)]
    if tlist[-1] != timesteps:
        tlist.append(timesteps)

    labels = batch[1][:numSamples].to(device)
    x0batch = batch[0][:numSamples].to(device)
    samples = [x0batch]
    rangeLabels = [[x0batch.min().item(), x0batch.max().item()]]

    for t in tlist:
        tbatch = torch.full((numSamples,), t-1, device=device, dtype=torch.int64)
        noise = torch.randn_like(x0batch)

        alphahatt = noiseScheduler.getNoiseLevel(tbatch).view(numSamples, 1, 1, 1)
        xtbatch = (torch.sqrt(alphahatt) * x0batch) + (torch.sqrt(1 - alphahatt) * noise)
        samples.append(xtbatch)
        rangeLabels.append([xtbatch.min().item(), xtbatch.max().item()])
    
    fig, axes = plt.subplots(nrows=numSamples,
                             ncols=len(samples),
                             figsize=(len(samples), numSamples))
    tlist = [0] + tlist

    if numSamples == 1:
        axes = axes[np.newaxis, :]

    for row in range(numSamples):
        for col in range(len(samples)):
            img = samples[col][row].detach().cpu()
            img = (torch.clamp(img, -1, 1) + 1) / 2
            permutedImg = img.permute(1,2,0).numpy()
            axes[row, col].imshow(permutedImg)
            axes[row, col].axis('off')
            if row == 0:
                axes[row, col].set_title(f"t={tlist[col]} [{rangeLabels[col][0]:.1f}, {rangeLabels[col][1]:.1f}]", fontsize=10)
            if col == 0 and classLabel:
                axes[row, col].set_title(f"{dataloader.dataset.classes[labels[row]]}", loc='left', fontsize=10)
        
    fig.text(0.5, 0.04, 't value', ha='center')
    plt.suptitle(f"{title} Forward diffusion")
    plt.tight_layout()
    plt.show()
